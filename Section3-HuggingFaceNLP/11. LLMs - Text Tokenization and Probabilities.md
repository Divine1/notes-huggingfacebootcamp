LLMs - Text Tokenization and Probabilities


```
text to text model

https://huggingface.co/openai-community/gpt2
```


```
import torch
torch.__version__

import transformers
transformers.__version__

from transformers import AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained("gpt2")
sentence = "what is the capital of france?"
sentence = "Preposterous, i'm flabbergasted!"
input_ids = tokenizer(sentence,return_tensors='pt').input_ids

tokenizer.decode(6197) # 'oster'
```
<img width="793" height="430" alt="image" src="https://github.com/user-attachments/assets/692a7224-979b-4a1b-9a75-27760386adb8" />


```
from transformers import AutoModelForCausalLM
gpt2 = AutoModelForCausalLM.from_pretrained("gpt2")






```
